{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, ArrayType, LongType, DoubleType, FloatType, DataType, DateType, TimestampType,DecimalType\n",
    "from pyspark.sql.functions import regexp_replace,row_number\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/27 11:13:47 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.197.132 instead (on interface ens33)\n",
      "22/08/27 11:13:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/08/27 11:13:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/27 11:14:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/08/27 11:14:05 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/08/27 11:14:05 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/08/27 11:14:05 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"Fact\")\n",
    " .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_df = spark.read.option('header','True').csv('/home/ubuntu/Documents/Beautiful_Soap/Profession/*.csv')\n",
    "\n",
    "state_city_df = spark.read.option('header','True').csv('/home/ubuntu/Documents/Beautiful_Soap/State/*.csv')\n",
    "\n",
    "state_salary_df = spark.read.option('header','True').csv('/home/ubuntu/Documents/Beautiful_Soap/State_Salary_Deviation/*.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---+\n",
      "|          Profession|Salary| Id|\n",
      "+--------------------+------+---+\n",
      "|              Design| 48574|  1|\n",
      "|           Logistics| 50358|  2|\n",
      "|            Research| 56399|  3|\n",
      "|        Construction| 57270|  4|\n",
      "|                  HR| 58029|  5|\n",
      "|Distribution and ...| 59591|  6|\n",
      "|          Production| 60046|  7|\n",
      "|       Marketing, PR| 60174|  8|\n",
      "|                  IT| 60563|  9|\n",
      "|            Engineer| 62564| 10|\n",
      "|             Banking| 62744| 11|\n",
      "|     Business Advice| 64173| 12|\n",
      "|              Lawyer| 68642| 13|\n",
      "|             Finance| 73847| 14|\n",
      "|              Doctor| 89539| 15|\n",
      "+--------------------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profession_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+---+\n",
      "|                City|            State| Id|\n",
      "+--------------------+-----------------+---+\n",
      "|          Reutlingen|Baden-Württemberg|  1|\n",
      "|                 Ulm|Baden-Württemberg|  2|\n",
      "|           Pforzheim|Baden-Württemberg|  3|\n",
      "|           Stuttgart|Baden-Württemberg|  4|\n",
      "|           Karlsruhe|Baden-Württemberg|  5|\n",
      "|Freiburg im Breisgau|Baden-Württemberg|  6|\n",
      "|           Heilbronn|Baden-Württemberg|  7|\n",
      "|          Heidelberg|Baden-Württemberg|  8|\n",
      "|            Mannheim|Baden-Württemberg|  9|\n",
      "|          Regensburg|          Bavaria| 10|\n",
      "|    Munich (München)|          Bavaria| 11|\n",
      "|Nuremberg (Nürnberg)|          Bavaria| 12|\n",
      "|            Würzburg|          Bavaria| 13|\n",
      "|          Ingolstadt|          Bavaria| 14|\n",
      "|               Fürth|          Bavaria| 15|\n",
      "|            Augsburg|          Bavaria| 16|\n",
      "|            Erlangen|          Bavaria| 17|\n",
      "|              Berlin|           Berlin| 18|\n",
      "|             Potsdam|      Brandenburg| 19|\n",
      "|              Bremen|           Bremen| 20|\n",
      "+--------------------+-----------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_city_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+---+\n",
      "|               State|Salary_Deviation| Id|\n",
      "+--------------------+----------------+---+\n",
      "|   Baden-Württemberg|             7.9|  1|\n",
      "|             Bavaria|             4.4|  2|\n",
      "|              Berlin|            -5.7|  3|\n",
      "|         Brandenburg|           -18.8|  4|\n",
      "|              Bremen|            -2.9|  5|\n",
      "|             Hamburg|             5.5|  6|\n",
      "|               Hesse|             7.2|  7|\n",
      "|        Lower Saxony|            -6.8|  8|\n",
      "|Mecklenburg-Vorpo...|           -22.0|  9|\n",
      "|North Rhine-Westp...|             1.1| 10|\n",
      "|Rhineland-Palatinate|            -1.4| 11|\n",
      "|            Saarland|            -4.4| 12|\n",
      "|              Saxony|           -18.5| 13|\n",
      "|       Saxony-Anhalt|           -19.5| 14|\n",
      "|  Schleswig-Holstein|            -9.8| 15|\n",
      "|           Thuringia|           -17.0| 16|\n",
      "+--------------------+----------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_salary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_salary_df.createOrReplaceTempView('state_salary_table')\n",
    "state_city_df.createOrReplaceTempView('state_city_table')\n",
    "profession_df.createOrReplaceTempView('profession_table')\n",
    "\n",
    "state_city_salary = spark.sql(\"SELECT t1.State,t1.Salary_Deviation,t2.City FROM state_salary_table t1 INNER JOIN state_city_table t2 ON t1.State LIKE t2.State\")\n",
    "\n",
    "#fact = state_salary_df.select('State','State_Salary_Deviation','City').join(state_city_df, state_salary_df.State == state_city_df.State).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_city_salary.createOrReplaceTempView('state_city_salary_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_df = spark.sql(\"SELECT t1.Profession, t1.Salary, t2.*,(Salary + (Salary*Salary_Deviation)/100 ) as Sal_Dev FROM profession_table as t1 CROSS JOIN state_city_salary_table as t2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_df.write.format('csv').option('header','true').mode('overwrite').option('encoding','UTF-8').save('Fact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
